# -*- coding: utf-8 -*-
"""Stock_price_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HZWFvmWPiOdPAjHsb40uelETcXSXaQ9U
"""

import pandas_datareader as pdr

df = pdr.get_data_tiingo('AAPL', api_key = '0028d666c44db615c875d61eefc5e9702164bb33')

df.to_csv('/content/drive/My Drive/Colab Notebook/AAPL.csv')

import pandas as pd

dataset = pd.read_csv('/content/drive/My Drive/Colab Notebook/AAPL.csv')
dataset

df = dataset.reset_index()['high']

df.shape

import matplotlib.pyplot as plt

plt.plot(df)

import numpy as np

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0,1))
df1 = scaler.fit_transform(np.array(df).reshape(-1,1))

df1.shape

training_size = int(len(df1)*0.75)
test_size = len(df1) - training_size

train_data , test_data = df1[0:training_size,:], df1[training_size:len(df1),:]

len(train_data)

import numpy as n
def create_dataset(dataset , time_steps):
   dataX , dataY = [] , []
   for i in range(len(dataset) - time_step -1):
      a = dataset[i:(i+time_step),0]
      dataX.append(a)
      dataY.append(dataset[i+time_step,0])
   return np.array(dataX) , np.array(dataY)

time_step = 100

X_train , Y_train = create_dataset(train_data , time_step)

X_test , Y_test = create_dataset(test_data , time_step)

X_train.shape

X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)
X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)

X_train.shape , X_test.shape

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM

model= Sequential()

model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))
model.add(LSTM(50,return_sequences=True))
model.add(LSTM(50))
model.add(Dense(1))

model.compile(loss = 'mean_squared_error', optimizer='adam')

model.summary()

model.fit(X_train ,Y_train , validation_data=(X_test,Y_test), epochs=100 , batch_size=64,verbose=1)

train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

train_predict = scaler.inverse_transform(train_predict)
test_predict = scaler.inverse_transform(test_predict)

import math
from sklearn.metrics import mean_squared_error
math.sqrt(mean_squared_error(Y_train , train_predict))

math.sqrt(mean_squared_error(Y_test , test_predict))

# shift train prediction for plotting

look_back = 100
trainPredictPlot = np.empty_like(df1)
trainPredictPlot[:,:] = np.nan
trainPredictPlot[look_back:len(train_predict)+look_back,:] = train_predict

# shift test predictions for plotting
testPredictPlot = np.empty_like(df1)
testPredictPlot[:,:] = np.nan
testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1,:] = test_predict

#plot baseline and predictions

plt.plot(scaler.inverse_transform(df1))
plt.plot(trainPredictPlot)
plt.plot(testPredictPlot)
plt.show()

len(test_data)

x_input = test_data[215:].reshape(1,-1)
x_input.shape

temp_input = list(x_input)
temp_input = temp_input[0].tolist()

from numpy import array
lst_output = []
n_steps = 100
i=0

while(i<30):
   if(len(temp_input)>100):
        x_input = np.array(temp_input[1:])
        x_input = x_input.reshape(1,-1)
        x_input = x_input.reshape((1, n_steps , 1))
        yhat = model.predict(x_input , verbose=0)
        temp_input.extend(yhat[0].tolist())
        temp_input = temp_input[1:]  
        lst_output.extend(yhat.tolist())
        i=i+1
   else:
       x_input = x_input.reshape((1, n_steps ,1))
       yhat = model.predict(x_input , verbose=0)
       temp_input.extend(yhat[0].tolist())
       lst_output.extend(yhat[0].tolist())
       i=i+1

lst_output